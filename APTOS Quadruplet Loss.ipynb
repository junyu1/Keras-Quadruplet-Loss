{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED=2019\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "from skimage.transform import resize\n",
    "from scipy.stats.mstats import gmean\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow import set_random_seed\n",
    "\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "from keras.utils import *\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.layers.convolutional import *\n",
    "from keras.layers.merge import *\n",
    "from keras.layers.normalization import *\n",
    "from keras.regularizers import *\n",
    "from keras.optimizers import *\n",
    "from keras.losses import *\n",
    "from keras.callbacks import *\n",
    "from keras.activations import *\n",
    "from keras.applications import *\n",
    "from keras.applications import mobilenetv2\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.legacy import interfaces\n",
    "\n",
    "from numba import jit\n",
    "\n",
    "import cv2\n",
    "\n",
    "from io import BytesIO\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import IPython\n",
    "from IPython.display import display\n",
    "from IPython.display import clear_output\n",
    "from IPython.core.display import display, HTML \n",
    "from IPython.display import Image, display_png\n",
    "\n",
    "import PIL\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm_notebook\n",
    "from multiprocessing import Process\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../input\")\n",
    "\n",
    "import json\n",
    "import math\n",
    "import string\n",
    "import collections\n",
    "import time\n",
    "\n",
    "from six.moves import xrange\n",
    "\n",
    "from efficientnet import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define L2 Normalized Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "def l2_norm(grad):\n",
    "    norm = K.sqrt(K.sum(K.square(grad))) + K.epsilon()\n",
    "    return norm\n",
    "\n",
    "class OptimizerWrapper(optimizers.Optimizer):\n",
    "\n",
    "    def __init__(self, optimizer):     \n",
    "        \n",
    "        self.optimizer = optimizers.get(optimizer)\n",
    "\n",
    "        # patch the `get_gradients` call\n",
    "        self._optimizer_get_gradients = self.optimizer.get_gradients\n",
    "\n",
    "    def get_gradients(self, loss, params):      \n",
    "        grads = self._optimizer_get_gradients(loss, params)\n",
    "        return grads\n",
    "\n",
    "    @interfaces.legacy_get_updates_support\n",
    "    def get_updates(self, loss, params):\n",
    "        # monkey patch `get_gradients`\n",
    "        self.optimizer.get_gradients = self.get_gradients\n",
    "\n",
    "        # get the updates\n",
    "        self.optimizer.get_updates(loss, params)\n",
    "\n",
    "        # undo monkey patch\n",
    "        self.optimizer.get_gradients = self._optimizer_get_gradients\n",
    "\n",
    "        return self.updates\n",
    "\n",
    "    def set_weights(self, weights):       \n",
    "        self.optimizer.set_weights(weights)\n",
    "\n",
    "    def get_weights(self):        \n",
    "        return self.optimizer.get_weights()\n",
    "\n",
    "    def get_config(self):       \n",
    "        # properties of NormalizedOptimizer\n",
    "        config = {'optimizer_name': self.optimizer.__class__.__name__.lower()}\n",
    "\n",
    "        # optimizer config\n",
    "        optimizer_config = {'optimizer_config': self.optimizer.get_config()}\n",
    "        return dict(list(optimizer_config.items()) + list(config.items()))\n",
    "\n",
    "    @property\n",
    "    def weights(self):\n",
    "        return self.optimizer.weights\n",
    "\n",
    "    @property\n",
    "    def updates(self):\n",
    "        return self.optimizer.updates\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @classmethod\n",
    "    def set_normalization_function(cls, name, func):\n",
    "        global _NORMS\n",
    "        _NORMS[name] = func\n",
    "\n",
    "    @classmethod\n",
    "    def get_normalization_functions(cls):        \n",
    "        global _NORMS\n",
    "        return sorted(list(_NORMS.keys()))\n",
    "\n",
    "\n",
    "class NormalizedOptimizer(OptimizerWrapper):\n",
    "\n",
    "    def __init__(self, optimizer, normalization='l2'):       \n",
    "        super(NormalizedOptimizer, self).__init__(optimizer)\n",
    "\n",
    "        if normalization not in _NORMS:\n",
    "            raise ValueError('`normalization` must be one of %s.\\n' \n",
    "                             'Provided was \"%s\".' % (str(sorted(list(_NORMS.keys()))), normalization))\n",
    "\n",
    "        self.normalization = normalization\n",
    "        self.normalization_fn = _NORMS[normalization]\n",
    "        self.lr = K.variable(1e-3, name='lr')\n",
    "\n",
    "    def get_gradients(self, loss, params):       \n",
    "        grads = super(NormalizedOptimizer, self).get_gradients(loss, params)\n",
    "        grads = [grad / self.normalization_fn(grad) for grad in grads]\n",
    "        return grads\n",
    "\n",
    "    def get_config(self):        \n",
    "        # properties of NormalizedOptimizer\n",
    "        config = {'normalization': self.normalization}\n",
    "\n",
    "        # optimizer config\n",
    "        base_config = super(NormalizedOptimizer, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):       \n",
    "        optimizer_config = {'class_name': config['optimizer_name'],\n",
    "                            'config': config['optimizer_config']}\n",
    "\n",
    "        optimizer = optimizers.get(optimizer_config)\n",
    "        normalization = config['normalization']\n",
    "\n",
    "        return cls(optimizer, normalization=normalization)\n",
    "\n",
    "\n",
    "_NORMS = {\n",
    "    'l2': l2_norm,\n",
    "}\n",
    "\n",
    "# register this optimizer to the global custom objects when it is imported\n",
    "get_custom_objects().update({'NormalizedOptimizer': NormalizedOptimizer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "class HorizontalDisplay:\n",
    "    def __init__(self, *args):\n",
    "        self.args = args\n",
    "\n",
    "    def _repr_html_(self):\n",
    "        template = '<div style=\"float: left; padding: 10px;\">{0}</div>'\n",
    "        return \"\\n\".join(template.format(arg._repr_html_())\n",
    "                         for arg in self.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "def showarray(a, fmt='png'):\n",
    "    a = np.uint8(a)\n",
    "    f = BytesIO()\n",
    "    PIL.Image.fromarray(a).save(f, fmt)\n",
    "    IPython.display.display(IPython.display.Image(data=f.getvalue()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../input/all-train-csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 5\n",
    "\n",
    "tr = pd.read_csv(\n",
    "    '../input/all-train-csv/train.csv',\n",
    "    dtype={\n",
    "        'id_code': str, \n",
    "        'diagnosis': str\n",
    "    }\n",
    ")\n",
    "\n",
    "tr15 = pd.read_csv(\n",
    "    '../input/all-train-csv/trainLabels.csv',\n",
    "    dtype={\n",
    "        'image': str, \n",
    "        'level': str\n",
    "    }\n",
    ")\n",
    "\n",
    "ts15 = pd.read_csv(\n",
    "    '../input/all-train-csv/retinopathy_solution.csv',\n",
    "    dtype={\n",
    "        'image': str, \n",
    "        'level': str\n",
    "    }\n",
    ")\n",
    "\n",
    "HorizontalDisplay(tr.head(), tr15.head(), ts15.head(), tr15.groupby(\"level\").count(), ts15.groupby(\"level\").count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete duplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md5s = pd.read_csv(\"../input/aptosmd5/strMd5.csv\")\n",
    "tr=tr[tr.id_code.isin(md5s[1 == md5s.strMd5_train_count].id_code.values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr.id_code = '../input/aptos-1519-hard-crop-480x480/cropped_resized_train_19_480/' + tr.id_code + '.jpg'\n",
    "tr15.image = '../input/aptos-1519-hard-crop-480x480/cropped_resized_train_15_480/' + tr15.image + '.jpg'\n",
    "ts15.image = '../input/aptos-1519-hard-crop-480x480/cropped_resized_test_15_480/' + ts15.image + '.jpg'\n",
    "HorizontalDisplay(tr.head(), tr15.head(), ts15.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show indivisual class image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image\n",
    "img = cv2.imread(\"../input/aptos-1519-hard-crop-480x480/cropped_resized_train_19_480/002c21358ce6.jpg\")\n",
    "showarray(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"../input/aptos-1519-hard-crop-480x480/cropped_resized_train_19_480/18b06f56ab27.jpg\")\n",
    "#showarray(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"../input/aptos-1519-hard-crop-480x480/cropped_resized_train_19_480/ffcf7b45f213.jpg\")\n",
    "###showarray(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"../input/aptos-1519-hard-crop-480x480/cropped_resized_train_19_480/03c85870824c.jpg\")\n",
    "#showarray(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"../input/aptos-1519-hard-crop-480x480/cropped_resized_train_19_480/eb1d37b71fd1.jpg\")\n",
    "#showarray(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "undersampled = []\n",
    "\n",
    "nsmpl = tr15.groupby(\"level\").count().image.min()\n",
    "\n",
    "for i in range(5):\n",
    "    undersampled.append(tr15[tr15.level == str(i)].sample(nsmpl, replace=True))\n",
    "    \n",
    "train = pd.concat(undersampled).sample(frac=1)\n",
    "HorizontalDisplay(tr15.groupby(\"level\").count(), train.groupby(\"level\").count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "undersampled = []\n",
    "\n",
    "nsmpl = ts15.groupby(\"level\").count().image.min()\n",
    "\n",
    "for i in range(5):\n",
    "    undersampled.append(ts15[ts15.level == str(i)].sample(nsmpl, replace=True))\n",
    "    \n",
    "train = pd.concat(undersampled+[train]).sample(frac=1)\n",
    "HorizontalDisplay(ts15.groupby(\"level\").count(), train.groupby(\"level\").count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 40\n",
    "batch_size = 8\n",
    "steps_per_epoch=100\n",
    "embedding_size = 128\n",
    "input_image_shape = (480, 480, 3)\n",
    "#input_image_shape = (28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quadruplet Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quadruplet_loss(alpha=1., beta=.5, batch_size=128):\n",
    "    \n",
    "    def _quadruplet_loss(y_true, y_pred):\n",
    "        del y_true    \n",
    "    \n",
    "   #     stronger_push = ())\n",
    "     #   weaker_push = tf.reduce_sum(()) \n",
    "        \n",
    "        quadruplet = \\\n",
    "            tf.reduce_sum(tf.maximum(tf.square(y_pred[:, 0]) - (1. - tf.square(y_pred[:, 1])) + alpha, 0)) \\\n",
    "            + tf.reduce_sum(tf.maximum(tf.square(y_pred[:, 0]) - (1. -  tf.square(y_pred[:, 2])) + beta, 0))\n",
    "#            tf.reduce_sum(tf.maximum(tf.square(y_pred[:, 0, 1]) - tf.square(y_pred[:, 1, 0]) + alpha, 0)) \\\n",
    "#            + tf.reduce_sum(tf.maximum(tf.square(y_pred[:, 0, 0]) - tf.square(y_pred[:, 1, 0]) + alpha, 0)) \\\n",
    "#            + tf.reduce_sum(tf.maximum(tf.square(y_pred[:, 0, 0]) - tf.square(y_pred[:, 2, 0]) + alpha, 0)) \\\n",
    "#            + tf.reduce_sum(tf.maximum(tf.square(y_pred[:, 0, 1]) - tf.square(y_pred[:, 2, 0]) + beta, 0))\n",
    "       # quadruplet = tf.square(stronger_push / alpha) + tf.square(weaker_push / beta)\n",
    "                                                                             \n",
    "        return quadruplet\n",
    "    \n",
    "    return _quadruplet_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate([[1]*5, [0]*5]).reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EfficientNetB0 backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_efficientnet = EfficientNetB0(\n",
    "#    include_top=False, \n",
    "#    weights=None, \n",
    "#    input_tensor=None, \n",
    "#    input_shape=input_image_shape, \n",
    "#    pooling='max', \n",
    "#    classes=5\n",
    "#)\n",
    "#_efficientnet.load_weights(\"../input/efficientnet-keras-weights-b0b5/efficientnet-b0_imagenet_1000_notop.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_efficientnet.layers[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_efficientnet = Model(inputs=_efficientnet.inputs, output=_efficientnet.layers[-1].output)\n",
    "#_efficientnet.layers.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_out = concatenate([GlobalMaxPooling2D(_efficientnet.layers[-3]), GlobalAveragePooling2D(_efficientnet.layers[-3])])\n",
    "#_efficientnet = Model(inputs=_efficientnet.inputs, output=_out)\n",
    "#_efficientnet.layers.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(len(_efficientnet.layers)-50):\n",
    "#    _efficientnet.layers[i].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentation_perimage(img):\n",
    "    x = tf.image.random_flip_left_right(img)\n",
    "    x = tf.random_crop(x, [400,400,3])\n",
    "    return x\n",
    "\n",
    "def standard_augmentation(inputs):\n",
    "    random_flip = tf.map_fn(augmentation_perimage, inputs)\n",
    "    resize = tf.image.resize_bicubic(random_flip, [480, 480])\n",
    "    random_rotate = tf.contrib.image.rotate(\n",
    "        resize,\n",
    "        np.random.randint(low=0, high=360, size=batch_size),\n",
    "        interpolation='BILINEAR'\n",
    "    )\n",
    "    return random_rotate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PeleeNet backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import keras.layers as layers\n",
    "\n",
    "def conv_bn_relu(input_tensor, ch, kernel, padding=\"same\", strides=1, weight_decay=5e-4):\n",
    "    x = layers.Conv2D(ch, kernel, padding=padding, strides=strides,\n",
    "                      kernel_regularizer=keras.regularizers.l2(weight_decay))(input_tensor)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    return layers.Activation(\"relu\")(x)\n",
    "\n",
    "def stem_block(input_tensor):\n",
    "    x = conv_bn_relu(input_tensor, 32, 3, strides=2)\n",
    "    branch1 = conv_bn_relu(x, 16, 1)\n",
    "    branch1 = conv_bn_relu(branch1, 32, 3, strides=2)\n",
    "    branch2 = layers.MaxPool2D(2)(x)\n",
    "    x = layers.Concatenate()([branch1, branch2])\n",
    "    return conv_bn_relu(x, 32, 1)\n",
    "\n",
    "def dense_block(input_tensor, num_layers, growth_rate, bottleneck_width):\n",
    "    x = input_tensor\n",
    "    growth_rate = int(growth_rate / 2)\n",
    "\n",
    "    for i in range(num_layers):\n",
    "        inter_channel = int(growth_rate*bottleneck_width/4) * 4\n",
    "        branch1 = conv_bn_relu(x, inter_channel, 1)\n",
    "        branch1 = conv_bn_relu(branch1, growth_rate, 3)\n",
    "\n",
    "        branch2 = conv_bn_relu(x, inter_channel, 1)\n",
    "        branch2 = conv_bn_relu(branch2, growth_rate, 3)\n",
    "        branch2 = conv_bn_relu(branch2, growth_rate, 3)\n",
    "        x = layers.Concatenate()([x, branch1, branch2])\n",
    "    return x\n",
    "\n",
    "def transition_layer(input_tensor, k, use_pooling=True):\n",
    "    x = conv_bn_relu(input_tensor, k, 1)\n",
    "    if use_pooling:\n",
    "        return layers.AveragePooling2D(2)(x)\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "def PeleeNet(input_shape=(224,224,3), use_stem_block=True, n_classes=1000, interrupt=False, is_train=False):\n",
    "    n_dense_layers = [3,4,8,6]\n",
    "    bottleneck_width = [1,2,4,4]\n",
    "    out_layers = [128,256,512,704]\n",
    "    growth_rate = 32\n",
    "\n",
    "    input = layers.Input(input_shape)\n",
    "    if is_train:\n",
    "        x = Lambda(standard_augmentation, output_shape=input_image_shape)(input)\n",
    "    else:\n",
    "        x = input\n",
    "    x = stem_block(x) if use_stem_block else x\n",
    "    for i in range(4):\n",
    "        x = dense_block(x, n_dense_layers[i], growth_rate, bottleneck_width[i])\n",
    "        use_pooling = i < 3\n",
    "        x = transition_layer(x, out_layers[i], use_pooling=use_pooling)\n",
    "        \n",
    "    if interrupt:\n",
    "        return keras.models.Model(input, x)\n",
    "    \n",
    "    x = layers.GlobalMaxPooling2D()(x)\n",
    "    x = layers.Dense(n_classes, activation=\"softmax\")(x)\n",
    "    return keras.models.Model(input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_peleenet = PeleeNet(input_image_shape, n_classes=NUM_CLASSES, interrupt=True, is_train=True)\n",
    "_peleenet.layers.pop(0)\n",
    "_peleenet = Model(inputs=_peleenet.inputs, output=_peleenet.layers[-1].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _swish(x, beta=1.0):\n",
    "    return x * K.sigmoid(beta * x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class swish(Layer):\n",
    "    \n",
    "    def __init__(self, beta=1.0, **kwargs):\n",
    "        super(swish, self).__init__(**kwargs)\n",
    "        self.supports_masking = True\n",
    "        self.beta = K.cast_to_floatx(beta)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \n",
    "        return _swish(inputs, beta=self.beta)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'beta': float(self.beta)}\n",
    "        base_config = super(swish, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quadruplet Deep Network (ReLU1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_in0 = (Input(input_image_shape))\n",
    "_in1 = (Input(input_image_shape))\n",
    "_in2 = (Input(input_image_shape))\n",
    "_in3 = (Input(input_image_shape))\n",
    "\n",
    "embedding = Sequential(name='embedding')\n",
    "embedding.add(Flatten())\n",
    "embedding.add(Dense(128, activation='elu', name='fc_0'))\n",
    "embedding.add(Dense(64, name='embedding_space'))\n",
    "\n",
    "ref = _peleenet(_in0)\n",
    "pos = _peleenet(_in1)\n",
    "neg = _peleenet(_in2)\n",
    "neg2 = _peleenet(_in3)\n",
    "\n",
    "ref = embedding(ref)\n",
    "pos = embedding(pos)\n",
    "neg = embedding(neg)\n",
    "neg2 = embedding(neg2)\n",
    "\n",
    "positive_pair = concatenate([ref,pos])\n",
    "negetive_pair = concatenate([ref,neg])\n",
    "negetive_pair_2 = concatenate([neg2,neg])\n",
    "\n",
    "metric = Sequential(name='metric')\n",
    "metric.add(Dense(1, name='diff_or_same'))\n",
    "metric.add(ReLU(max_value=1.))\n",
    "\n",
    "positive_pair_distance = metric(positive_pair)\n",
    "negetive_pair_distance = metric(negetive_pair)\n",
    "negetive_pair_2_distance = metric(negetive_pair_2)\n",
    "\n",
    "_out0 = Reshape((-1, 1))(positive_pair_distance)\n",
    "_out1 = Reshape((-1, 1))(negetive_pair_distance)\n",
    "_out2 = Reshape((-1, 1))(negetive_pair_2_distance)\n",
    "\n",
    "probs = concatenate([_out0, _out1, _out2], axis=1, name='probs')\n",
    "\n",
    "model = Model(inputs=[_in0, _in1, _in2, _in3], outputs=probs)#[logits_ref, logits_pos, logits_neg, logits_neg2, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.pyimagesearch.com/2018/06/04/keras-multiple-outputs-and-multiple-losses/\n",
    "# losses = {\n",
    "# \t\"category_output\": \"categorical_crossentropy\",\n",
    "# \t\"color_output\": \"categorical_crossentropy\",\n",
    "# }\n",
    "# lossWeights = {\"category_output\": 1.0, \"color_output\": 1.0}\n",
    "#  \n",
    "# # initialize the optimizer and compile the model\n",
    "# print(\"[INFO] compiling model...\")\n",
    "# opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "# model.compile(optimizer=opt, loss=losses, loss_weights=lossWeights,\n",
    "# metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quadruplet_loss_with_binary_cross_entropy(alpha=.2, beta=.1, batch_size=128):\n",
    "    # bs , 3 , 1\n",
    "    def _quadruplet_loss(y_true, y_pred):\n",
    "        del y_true\n",
    "        \n",
    "        quadruplet = \\\n",
    "            tf.maximum(tf.square(1. - y_pred[:, 0]) - tf.square(1. - y_pred[:, 1]) + alpha, 0) \\\n",
    "            + tf.maximum(tf.square(1. - y_pred[:, 0]) - tf.square(1. - y_pred[:, 2]) + beta, 0)\n",
    "                                                                             \n",
    "        return \\\n",
    "            quadruplet \\\n",
    "            + binary_crossentropy(\n",
    "                tf.convert_to_tensor(np.concatenate([np.ones((batch_size//2, 1)), np.zeros((batch_size//2, 1))]), dtype=tf.float32), \n",
    "                tf.reshape(y_pred[:batch_size//2, :2], (batch_size, 1))\n",
    "            )\n",
    "    \n",
    "    return _quadruplet_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quadruplet_loss(alpha=.5, beta=.2, batch_size=128):\n",
    "    # bs , 3 , 1\n",
    "    def _quadruplet_loss(y_true, y_pred):\n",
    "        del y_true\n",
    "        \n",
    "        quadruplet = \\\n",
    "            tf.maximum(tf.square(1. - y_pred[:, 0]) - tf.square(1. - y_pred[:, 1]) + alpha, 0) \\\n",
    "            + tf.maximum(tf.square(1. - y_pred[:, 0]) - tf.square(1. - y_pred[:, 2]) + beta, 0)\n",
    "                                                                             \n",
    "        return quadruplet\n",
    "    \n",
    "    return _quadruplet_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGD(1e-3, momentum=0.9, nesterov=True)\n",
    "sgd = NormalizedOptimizer(sgd, normalization='l2')\n",
    "\n",
    "losses = {\n",
    "  #  \"logits\": \"kullback_leibler_divergence\", #lambda y_true, y_pred: mean_squared_error(y_true, K.clip(y_pred, 0., 4.)), #tf.nn.softmax_cross_entropy_with_logits_v2,\n",
    "    \"probs\": quadruplet_loss_with_binary_cross_entropy(alpha=.2, beta=.1,batch_size=batch_size),\n",
    "}\n",
    "lossWeights = {\"logits\": .5, \"probs\": 1.}\n",
    "\n",
    "model.compile(\n",
    "    optimizer= SGD(1e-5, momentum=0.9, nesterov=True),\n",
    "    loss=quadruplet_loss(alpha=.5, beta=.2,batch_size=batch_size),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sgd = SGD(1e-5, momentum=0.9, nesterov=True)\n",
    "#sgd = NormalizedOptimizer(sgd, normalization='l2')\n",
    "#\n",
    "#model.compile(\n",
    "#    optimizer=sgd,\n",
    "#    loss=quadruplet_loss(alpha=.8, beta=.6,batch_size=batch_size)\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RAdamW(\n",
    "#        lr=1e-6, beta_1=0.9, beta_2=0.999,\n",
    "#        epsilon=None, decay=0., weight_decay=0.025, amsgrad=True,\n",
    "#        total_steps=steps_per_epoch*epochs, warmup_proportion=0.1, min_lr=1e-7, \n",
    "#        batch_size=batch_size, samples_per_epoch=epochs*batch_size,\n",
    "#        epochs=epochs, eta=1.\n",
    "#    )numpy.random.random()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit()\n",
    "def preprocess(im, erase_rate=0.2, src_width=480, src_height=480):\n",
    "    \n",
    "    # subtract_median_bg_image\n",
    "    k = np.max(im.shape)//20*2+1\n",
    "    bg = cv2.medianBlur(im, k)\n",
    "    subtract_median_bg_image = cv2.addWeighted (im, 4, bg, -4, 128)\n",
    "    \n",
    "    # random erase\n",
    "    mask_width, mask_height = np.random.randint(0, src_width * erase_rate), np.random.randint(0, src_height * erase_rate)\n",
    "    offset_x = np.random.randint(0, src_width-mask_width+1)\n",
    "    offset_y = np.random.randint(0, src_height-mask_height+1)          \n",
    "    \n",
    "    mask = np.random.random(size=(mask_width, mask_height, 3))\n",
    "    img[offset_x:offset_x+mask_width, offset_y:offset_y+mask_height, :] = mask\n",
    "    \n",
    "    return img        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quadra_generator(df, file_name_column, label_column, batch_size, input_shape):\n",
    "\n",
    "    labels = df[label_column].unique()\n",
    "\n",
    "    file_names_by_class = [df[df[label_column] == label][file_name_column].tolist() for label in labels]\n",
    "\n",
    "    labels = [int(label) for label in labels]\n",
    "\n",
    "    while True:\n",
    "        \n",
    "        x = np.empty((4, batch_size, *input_shape))\n",
    "        y = np.zeros((4, batch_size, NUM_CLASSES))\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            \n",
    "            ref_pos_idx, neg_idx, neg2_idx = np.random.choice(labels, size=3, replace=False, p=None)\n",
    "\n",
    "            ref_file_name, pos_file_name = np.random.choice(file_names_by_class[ref_pos_idx], size=2, replace=False)\n",
    "\n",
    "            img = cv2.imread(ref_file_name)\n",
    "            x[0, i] = preprocess(img )#\n",
    "            img = cv2.imread(pos_file_name)\n",
    "            x[1, i] = preprocess(img ) #\n",
    "            img =  cv2.imread(np.random.choice(file_names_by_class[neg_idx]))\n",
    "            x[2, i] = preprocess(img ) #\n",
    "            img = cv2.imread(np.random.choice(file_names_by_class[neg2_idx]))\n",
    "            x[3, i] = preprocess(img)#  - img.mean()\n",
    "            \n",
    "            y[0, i, ref_pos_idx] = 1.\n",
    "            y[1, i, ref_pos_idx] = 1.\n",
    "            y[2, i, neg_idx] = 1.\n",
    "            y[3, i, neg2_idx] = 1.\n",
    "\n",
    "\n",
    "        #x[:, :, :, :, 0] = 0. # ignore red channel\n",
    "        \n",
    "        x = x / 255.\n",
    "\n",
    "        yield [x[0], x[1], x[2], x[3]],  np.empty(batch_size)#y[0], y[1], y[2], y[3],"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(\n",
    "    quadra_generator(train, \"image\", \"level\", batch_size, input_image_shape),\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=epochs,\n",
    "    validation_data=quadra_generator(tr, \"id_code\", \"diagnosis\", batch_size, input_image_shape),\n",
    "    validation_steps=16,\n",
    "#    callbacks=[checkpoint, lr_decay]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"quadruplet.h5\")\n",
    "######################################################################\n",
    "\n",
    "_peleenet = PeleeNet(input_image_shape, n_classes=NUM_CLASSES, interrupt=True, is_train=False)\n",
    "_peleenet.layers.pop(0)\n",
    "_peleenet = Model(inputs=_peleenet.inputs, output=_peleenet.layers[-1].output)\n",
    "\n",
    "ref = _peleenet(_in0)\n",
    "ref = embedding(ref)\n",
    "model = Model(inputs=_in0, outputs=ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_in = Input(input_image_shape)\n",
    "#\n",
    "#ref = _efficientnet(_in)\n",
    "#\n",
    "#embedding = Sequential(name='embedding')\n",
    "##embedding.add(Flatten())\n",
    "#embedding.add(Dense(512, name='embedding_layer_1'))\n",
    "#embedding.add(Dropout(rate=0.1))\n",
    "#embedding.add(Dense(64, name='embedding_layer_2'))\n",
    "#_out = embedding(ref)\n",
    "#\n",
    "#model = Model(inputs=_in, outputs=_out)\n",
    "#model.compile(\n",
    "#    optimizer=\"adam\", \n",
    "#    loss=quadruplet_loss(alpha=1., beta=0.5, batch_size=batch_size)\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"quadruplet.h5\", by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr15 = pd.read_csv(\n",
    "    '../input/all-train-csv/trainLabels.csv',\n",
    "    dtype={\n",
    "        'image': str, \n",
    "        'level': str\n",
    "    }\n",
    ")\n",
    "tr15.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr19 = pd.read_csv(\n",
    "    '../input/all-train-csv/train.csv',\n",
    "    dtype={\n",
    "        'id_code': str, \n",
    "        'diagnosis': str\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "undersampled = []\n",
    "\n",
    "nsmpl = tr15.groupby(\"level\").count().image.min()\n",
    "\n",
    "for i in range(5):\n",
    "    undersampled.append(tr15[tr15.level == str(i)].sample(nsmpl, replace=True))\n",
    "    \n",
    "train = pd.concat(undersampled).sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.image = train.image + '.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen=ImageDataGenerator(\n",
    "    rescale=1./255 #,\n",
    "#    shear_range=0.,\n",
    "#    zoom_range=0.2,\n",
    "#    horizontal_flip=False,\n",
    "#    vertical_flip = True,\n",
    "#    rotation_range=360\n",
    ")\n",
    "\n",
    "test_generator=test_datagen.flow_from_dataframe(\n",
    "    dataframe=train,\n",
    "    directory=\"../input/aptos-1519-hard-crop-480x480/cropped_resized_train_15_480\",\n",
    "    x_col='image',\n",
    "    y_col=None,\n",
    "    target_size=(480, 480),\n",
    "    batch_size=1,\n",
    "    class_mode=None,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator.reset()\n",
    "\n",
    "pred=model.predict_generator(\n",
    "   test_generator,\n",
    "   steps=test_generator.n//test_generator.batch_size,\n",
    "   verbose=1\n",
    ")\n",
    "\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = umap.UMAP().fit_transform(pred)\n",
    "\n",
    "plt.scatter(embedding[:,0],embedding[:,1],c=train.level.astype(int),cmap=cm.tab10)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduced = TSNE(n_components=2).fit_transform(pred)\n",
    "\n",
    "plt.scatter(X_reduced[:, 0], X_reduced[:, 1], c=train.level.astype(int),cmap=cm.tab10)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduced = PCA(n_components=2).fit_transform(pred)\n",
    "\n",
    "plt.scatter(X_reduced[:, 0], X_reduced[:, 1], c=train.level.astype(int),cmap=cm.tab10)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(gamma='auto')\n",
    "svm.fit(pred, train.level)\n",
    "#svm.score(pred,train.level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr19 = pd.read_csv(\n",
    "    '../input/all-train-csv/train.csv',\n",
    "    dtype={\n",
    "        'id_code': str, \n",
    "        'diagnosis': str\n",
    "    }\n",
    ")\n",
    "\n",
    "tr19.id_code = tr19.id_code + '.jpg'\n",
    "\n",
    "undersampled = []\n",
    "\n",
    "nsmpl = tr19.groupby(\"diagnosis\").count().id_code.min()\n",
    "\n",
    "for i in range(5):\n",
    "    undersampled.append(tr19[tr19.diagnosis == str(i)].sample(nsmpl, replace=True))\n",
    "    \n",
    "train = pd.concat(undersampled).sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen=ImageDataGenerator(\n",
    "    rescale=1./255 #,\n",
    "#    shear_range=0.,\n",
    "#    zoom_range=0.2,\n",
    "#    horizontal_flip=False,\n",
    "#    vertical_flip = True,\n",
    "#    rotation_range=360\n",
    ")\n",
    "\n",
    "test_generator=test_datagen.flow_from_dataframe(\n",
    "    dataframe=train,\n",
    "    directory=\"../input/aptos-1519-hard-crop-480x480/cropped_resized_train_19_480\",\n",
    "    x_col='id_code',\n",
    "    y_col=None,\n",
    "    target_size=(480, 480),\n",
    "    batch_size=1,\n",
    "    class_mode=None,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator.reset()\n",
    "\n",
    "pred=model.predict_generator(\n",
    "   test_generator,\n",
    "   steps=test_generator.n//test_generator.batch_size,\n",
    "   verbose=1\n",
    ")\n",
    "\n",
    "pred.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
